function [ h0, h1, h2 ] = Gradient_h0( X, D, h0, h1, h2 )
%GRADIENT_COMPLEX Summary of this function goes here
%   Detailed explanation goes here
%load signal_1_inout.mat

X = X / power(2, 16);
D = D / power(2, 16);

i = 0 + 1i;

error_of_epoch = zeros(1, 10);

for l = 1:1000
    
    y = zeros(1, length(X)); %convolution(X, h0, 0) .* convolution(convolution(X, h2, 1), h1, 0);
    e = zeros(1, length(X));
    error = zeros(1, length(X));
    error_not_norm = zeros(1, length(X));
    error_norm = zeros(1, length(X));
    J_h0 = zeros(1, length(X));
    J_h1 = zeros(1, length(X));
    J_h2 = zeros(1, length(X));
    
    
    for k = length(h0):length(X)

        %mult = convolution(X(k - length(h0) + 1:k), h0, 0) .* convolution(convolution(X(k - length(h0) + 1:k), h2, 1), h1, 0);

        %all non-linear transform
        y_current = Generate(X(k - length(h0) + 1:k),h0, h1, h2);

        %simple linear filter
        %y_current = convolution(X(k - length(h0) + 1:k), h0, 0);
        y(k) = y_current(length(y_current)); % current y

        e(k) = D(k) - y(k); %error in complex
        error_norm(k) = e(k) * conj(e(k)); %error

        %h0---------------------------------------------------------------------
        outB1 = convolution(convolution(X(k - length(h0) + 1:k),h2,1), h1, 0); %output of H1-block. CONJUG
        outB1 = outB1(length(outB1));
        learning_rate_h0 = 0.1;

        for n = 1:length(h0)

            J_h0(n) =  e(k) * conj(outB1) * conj(X(k - n + 1));

            corr = learning_rate_h0 * J_h0(n);
            h0(n) = h0(n) + corr;

        end

         %h1---------------------------------------------------------------------

         learning_rate_h1 = 0.1;
         outB0 = convolution(X(k - length(h0) + 1:k), h0, 0); %output of H0-block.
         outB0 = outB0(length(outB0));
 
         for n = 1:length(h1)  
 
             f = convolution(X(k - length(h0) + 1:k), h2, 1);
             J_h1(n) =  e(k) * conj(outB0) * conj(f(length(h0) - n + 1));
 
             corr = learning_rate_h1 * J_h1(n);
             h1(n) = h1(n) + corr;
 
         end     
        
        
        %h2---------------------------------------------------------------------

        learning_rate_h2 = 0.1;
        outB0 = convolution(X(k - length(h0) + 1:k), h0, 0); %output of H0-block.
        outB0 = outB0(length(outB0));
        
        outB1 = convolution(convolution(X(k - length(h0) + 1:k), ones(1, length(h0)), 1), fliplr(h1), 0);
        outB1 = outB1(length(outB1));

        for n = 1:length(h1)  

            f = convolution(X(k - length(h0) + 1:k), ones(1, length(h0)), 1);
            J_h2(n) =  e(k) * conj(outB0) * conj(outB1) * conj(f(n));

            corr = learning_rate_h2 * J_h2(n);
            h2(n) = h2(n) + corr;

        end 
    
    end

    error_of_epoch(l) = nmse(D, e);
    
  
 
    
end
    
end


--------------------------------------------------------------------------------------------------------------------------------
# for complex

function [ h0 ] = Matrix_LMS_1( X, Des, h0, h1, h2)
%MATRIX_LMS Summary of this function goes here
%   Detailed explanation goes here

%X_h1 = convolution(convolution(X, h2, 1), h1, 0);    
    %%
    
    epoch = 10000


    %x_comp = (X(1:1000));
    %y_comp = conv(x_comp, h0, 'same') .* conv(f(x_comp, h2), h1, 'same');
    
    x_comp = X;
    y_comp = Des;
      
    e = zeros(1, epoch);

    %y_comp_ = filter((h0), 1, x_comp) .* filter((h1), 1, x_comp); 
    %y_comp = convolution(x_comp, h0, 0) .* convolution(x_comp, h1, 0);
    
    %h1_pred = h1;
    %h2_pred = h2;
    
    h1_pred = [0+0i, 1+1i, 0+0i];
    h2_pred = [0+0i, 1+1i, 0+0i];
    for l = 1:epoch

        % h0 ------------------------------------------
        outB1 = conv(f(x_comp, h2_pred), h1_pred, 'same');
         

        %Vandermond matrix construction
        V = zeros(3, length(x_comp));
        D = 1;
        for k = -D:D
            V(k + D + 1, :) = delay(x_comp, k) .* outB1;
        end

       
        %xb = toeplitz(sig,[sig(1), zeros(1,2)]);
        xb = V.';
        h0_pred = pinv(xb' * xb) * xb' * y_comp.';
    
        
        % h1 -------------------------------------------
         outB0 = conv(x_comp, h0_pred, 'same');
         outB2 = f(x_comp, h2_pred);

        %Vandermond matrix construction
         V = zeros(3, length(x_comp));
         D = 1;
         for k = -D:D
             V(k + D + 1, :) = delay(outB2, k) .* outB0;
         end

        %xb = toeplitz(sig,[sig(1), zeros(1,2)]);
        xb = V.';
        h1_pred = pinv(xb' * xb) * xb' * y_comp.';
        
        
        % h2----------------------------------------------      
        outB0 = conv(x_comp, h0_pred, 'same');

        %Vandermond matrix construction
        V = zeros(3, length(x_comp));
        V1 = zeros(3, length(x_comp));
    
        D = 1;
        for k = -D:D
            V(k + D + 1, :) = conv(power(abs(x_comp), k + D), h1_pred, 'same') .* outB0;
        
            % correction test---------------------------------------
            V1(k + D + 1, :) = conv(power(abs(x_comp), k + D) * h2(k + D + 1), h1, 'same');  
            V12 = sum(V1);
            Y_ = V12 .* outB0;
            %--------------------------------------------------------
            
        end
        xb = V.';
        h2_pred = pinv(xb' * xb) * xb' * y_comp.';
    
        Y_pred = conv(x_comp, h0_pred, 'same') .* conv(f(x_comp, h2_pred), h1_pred, 'same');
        e(l) = nmse(y_comp, y_comp - Y_pred);
       
    end



end


function [ Y ] = f(X, h)
 
Y = zeros(1, length(X));
 
for i = 1:length(X)   
        for j = 1:length(h)
                Y(i) = Y(i) + h(j) * power(abs(X(i)), j-1);
        end
end
 
end


#-----------------------------------------------------------------------------------------------------------------
#for real nonlinear (3 blocks)

function [ h0 ] = Matrix_LMS(X)
 
epoch = 100000
 
h0 = [0.1,0.2,0.3]
h1 = [0.4,0.2,0.1]
h2 = [0.1,0.2,0.3]
 
%%
Y = conv(X, h0, 'same') .* conv(f(X, h2), h1, 'same');
L = length(X);
 
 
e = zeros(1, length(X));
 
h1_pred = [0,1,0];
h2_pred = [0,1,0];
for l = 1:epoch
    
    % h0----------------------------------------------
    outB1 = conv(f(X, h2_pred), h1_pred, 'same');
    
    %Vandermond matrix construction
    V = zeros(3, L);
    D = 1;
    for k = -D:D
        V(k + D + 1, :) = delay(X, k) .* outB1;
    end
    
    %xb = toeplitz(sig,[sig(1), zeros(1,2)]);
    xb = V';
    h0_pred = pinv(xb' * xb) * xb' * Y';
 
    
    % h1----------------------------------------------      
    outB0 = conv(X, h0_pred, 'same');
    outB2 = f(X, h2_pred);
    %sig = X .* outB0;
 
    %xb = toeplitz(sig,[sig(1), zeros(1,2)]);
    %Vandermond matrix construction
    V = zeros(3, L);
    D = 1;
    for k = -D:D
        V(k + D + 1, :) = delay(outB2, k) .* outB0;
    end
    
    xb = V';
    h1_pred = pinv(xb' * xb) * xb' * Y';
    
    
    % h2----------------------------------------------      
    outB0 = conv(X, h0_pred, 'same');

    %Vandermond matrix construction
    V = zeros(3, L);
    V1 = zeros(3, L);
    
    D = 1;
    for k = -D:D
        V(k + D + 1, :) = conv(power(abs(X), k + D), h1_pred, 'same') .* outB0;
        
        % correction test---------------------------------------
        V1(k + D + 1, :) = conv(power(abs(X), k + D) * h2(k + D + 1), h1, 'same');  
        V12 = sum(V1);
        Y_ = V12 .* outB0;
        %--------------------------------------------------------
        
        
    end
    
    xb = V';
    h2_pred = pinv(xb' * xb) * xb' * Y';
    
    Y_pred = conv(X, h0_pred, 'same') .* conv(f(X, h2_pred), h1_pred, 'same');
    
    e(l) = sum(power((Y - Y_pred), 2));
 
end
 
end
 
 
function [ Y ] = f(X, h)
 
Y = zeros(1, length(X));
 
for i = 1:length(X)   
        for j = 1:length(h)
                Y(i) = Y(i) + h(j) * power(abs(X(i)), j-1);
        end
end
 
end
 

#-----------------------------------------------------------------------------------------------------------------
#for real linear (1 blocks)

function [ h2 ] = Matrix_LMS_2(X)
 
epoch = 100000
 
h0 = [0.1,0.2,0.3]
h1 = [0.4,0.2,0.1]
h2 = [0.1,0.2,0.3]
 
%%
Y = f(X, h2);
L = length(X);
 
 
e = zeros(1, length(X));
 
h1_pred = [0,1,0];
h2_pred = [0,1,0];
for l = 1:epoch
    
    
    
    % h2----------------------------------------------      

    %Vandermond matrix construction
    V = zeros(3, L);
    V1 = zeros(3, L);
    
    D = 1;
    %h1_pred = fliplr(h1);
    for k = -D:D
        V(k + D + 1, :) = power(abs(X), k + D);
        
        % correction test---------------------------------------
        V1(k + D + 1, :) = power(abs(X), k + D);  
        V12 = sum(V1);
        Y_ = V12;
        %--------------------------------------------------------
        
        
    end
    
    xb = V';
    h2_pred = pinv(xb' * xb) * xb' * Y';
    
    Y_pred = conv(f(X, h2_pred), h1_pred, 'same');
    
    e(l) = sum(power((Y - Y_pred), 2));
 
end
 
end
 
 
function [ Y ] = f(X, h)
 
Y = zeros(1, length(X));
 
for i = 1:length(X)   
        for j = 1:length(h)
                Y(i) = Y(i) + h(j) * power(abs(X(i)), j-1);
        end
end
 
end
 










