function [ h0, h1, h2 ] = Gradient_h0( X, D, h0, h1, h2 )
%GRADIENT_COMPLEX Summary of this function goes here
%   Detailed explanation goes here
%load signal_1_inout.mat

X = X / power(2, 16);
D = D / power(2, 16);

i = 0 + 1i;

error_of_epoch = zeros(1, 10);

for l = 1:1000
    
    y = zeros(1, length(X)); %convolution(X, h0, 0) .* convolution(convolution(X, h2, 1), h1, 0);
    e = zeros(1, length(X));
    error = zeros(1, length(X));
    error_not_norm = zeros(1, length(X));
    error_norm = zeros(1, length(X));
    J_h0 = zeros(1, length(X));
    J_h1 = zeros(1, length(X));
    J_h2 = zeros(1, length(X));
    
    
    for k = length(h0):length(X)

        %mult = convolution(X(k - length(h0) + 1:k), h0, 0) .* convolution(convolution(X(k - length(h0) + 1:k), h2, 1), h1, 0);

        %all non-linear transform
        y_current = Generate(X(k - length(h0) + 1:k),h0, h1, h2);

        %simple linear filter
        %y_current = convolution(X(k - length(h0) + 1:k), h0, 0);
        y(k) = y_current(length(y_current)); % current y

        e(k) = D(k) - y(k); %error in complex
        error_norm(k) = e(k) * conj(e(k)); %error

        %h0---------------------------------------------------------------------
        outB1 = convolution(convolution(X(k - length(h0) + 1:k),h2,1), h1, 0); %output of H1-block. CONJUG
        outB1 = outB1(length(outB1));
        learning_rate_h0 = 0.1;

        for n = 1:length(h0)

            J_h0(n) =  e(k) * conj(outB1) * conj(X(k - n + 1));

            corr = learning_rate_h0 * J_h0(n);
            h0(n) = h0(n) + corr;

        end

         %h1---------------------------------------------------------------------

         learning_rate_h1 = 0.1;
         outB0 = convolution(X(k - length(h0) + 1:k), h0, 0); %output of H0-block.
         outB0 = outB0(length(outB0));
 
         for n = 1:length(h1)  
 
             f = convolution(X(k - length(h0) + 1:k), h2, 1);
             J_h1(n) =  e(k) * conj(outB0) * conj(f(length(h0) - n + 1));
 
             corr = learning_rate_h1 * J_h1(n);
             h1(n) = h1(n) + corr;
 
         end     
        
        
        %h2---------------------------------------------------------------------

        learning_rate_h2 = 0.1;
        outB0 = convolution(X(k - length(h0) + 1:k), h0, 0); %output of H0-block.
        outB0 = outB0(length(outB0));
        
        outB1 = convolution(convolution(X(k - length(h0) + 1:k), ones(1, length(h0)), 1), fliplr(h1), 0);
        outB1 = outB1(length(outB1));

        for n = 1:length(h1)  

            f = convolution(X(k - length(h0) + 1:k), ones(1, length(h0)), 1);
            J_h2(n) =  e(k) * conj(outB0) * conj(outB1) * conj(f(n));

            corr = learning_rate_h2 * J_h2(n);
            h2(n) = h2(n) + corr;

        end 
    
    end

    error_of_epoch(l) = nmse(D, e);
    
  
 
    
end
    
end


--------------------------------------------------------------------------------------------------------------------------------
# for complex

function [ h0 ] = Matrix_LMS_1( X, Des, h0, h1, h2)
%MATRIX_LMS Summary of this function goes here
%   Detailed explanation goes here

%X_h1 = convolution(convolution(X, h2, 1), h1, 0);    
    %%
    
    epoch = 10000


    %x_comp = (X(1:1000));
    %y_comp = conv(x_comp, h0, 'same') .* conv(f(x_comp, h2), h1, 'same');
    
    x_comp = X;
    y_comp = Des;
      
    e = zeros(1, epoch);

    %y_comp_ = filter((h0), 1, x_comp) .* filter((h1), 1, x_comp); 
    %y_comp = convolution(x_comp, h0, 0) .* convolution(x_comp, h1, 0);
    
    %h1_pred = h1;
    %h2_pred = h2;
    
    h1_pred = [0+0i, 1+1i, 0+0i];
    h2_pred = [0+0i, 1+1i, 0+0i];
    for l = 1:epoch

        % h0 ------------------------------------------
        outB1 = conv(f(x_comp, h2_pred), h1_pred, 'same');
         

        %Vandermond matrix construction
        V = zeros(3, length(x_comp));
        D = 1;
        for k = -D:D
            V(k + D + 1, :) = delay(x_comp, k) .* outB1;
        end

       
        %xb = toeplitz(sig,[sig(1), zeros(1,2)]);
        xb = V.';
        h0_pred = pinv(xb' * xb) * xb' * y_comp.';
    
        
        % h1 -------------------------------------------
         outB0 = conv(x_comp, h0_pred, 'same');
         outB2 = f(x_comp, h2_pred);

        %Vandermond matrix construction
         V = zeros(3, length(x_comp));
         D = 1;
         for k = -D:D
             V(k + D + 1, :) = delay(outB2, k) .* outB0;
         end

        %xb = toeplitz(sig,[sig(1), zeros(1,2)]);
        xb = V.';
        h1_pred = pinv(xb' * xb) * xb' * y_comp.';
        
        
        % h2----------------------------------------------      
        outB0 = conv(x_comp, h0_pred, 'same');

        %Vandermond matrix construction
        V = zeros(3, length(x_comp));
        V1 = zeros(3, length(x_comp));
    
        D = 1;
        for k = -D:D
            V(k + D + 1, :) = conv(power(abs(x_comp), k + D), h1_pred, 'same') .* outB0;
        
            % correction test---------------------------------------
            V1(k + D + 1, :) = conv(power(abs(x_comp), k + D) * h2(k + D + 1), h1, 'same');  
            V12 = sum(V1);
            Y_ = V12 .* outB0;
            %--------------------------------------------------------
            
        end
        xb = V.';
        h2_pred = pinv(xb' * xb) * xb' * y_comp.';
    
        Y_pred = conv(x_comp, h0_pred, 'same') .* conv(f(x_comp, h2_pred), h1_pred, 'same');
        e(l) = nmse(y_comp, y_comp - Y_pred);
       
    end



end


function [ Y ] = f(X, h)
 
Y = zeros(1, length(X));
 
for i = 1:length(X)   
        for j = 1:length(h)
                Y(i) = Y(i) + h(j) * power(abs(X(i)), j-1);
        end
end
 
end


#-----------------------------------------------------------------------------------------------------------------
#for real nonlinear (3 blocks)

function [ h0 ] = Matrix_LMS(X)
 
epoch = 100000
 
h0 = [0.1,0.2,0.3]
h1 = [0.4,0.2,0.1]
h2 = [0.1,0.2,0.3]
 
%%
Y = conv(X, h0, 'same') .* conv(f(X, h2), h1, 'same');
L = length(X);
 
 
e = zeros(1, length(X));
 
h1_pred = [0,1,0];
h2_pred = [0,1,0];
for l = 1:epoch
    
    % h0----------------------------------------------
    outB1 = conv(f(X, h2_pred), h1_pred, 'same');
    
    %Vandermond matrix construction
    V = zeros(3, L);
    D = 1;
    for k = -D:D
        V(k + D + 1, :) = delay(X, k) .* outB1;
    end
    
    %xb = toeplitz(sig,[sig(1), zeros(1,2)]);
    xb = V';
    h0_pred = pinv(xb' * xb) * xb' * Y';
 
    
    % h1----------------------------------------------      
    outB0 = conv(X, h0_pred, 'same');
    outB2 = f(X, h2_pred);
    %sig = X .* outB0;
 
    %xb = toeplitz(sig,[sig(1), zeros(1,2)]);
    %Vandermond matrix construction
    V = zeros(3, L);
    D = 1;
    for k = -D:D
        V(k + D + 1, :) = delay(outB2, k) .* outB0;
    end
    
    xb = V';
    h1_pred = pinv(xb' * xb) * xb' * Y';
    
    
    % h2----------------------------------------------      
    outB0 = conv(X, h0_pred, 'same');

    %Vandermond matrix construction
    V = zeros(3, L);
    V1 = zeros(3, L);
    
    D = 1;
    for k = -D:D
        V(k + D + 1, :) = conv(power(abs(X), k + D), h1_pred, 'same') .* outB0;
        
        % correction test---------------------------------------
        V1(k + D + 1, :) = conv(power(abs(X), k + D) * h2(k + D + 1), h1, 'same');  
        V12 = sum(V1);
        Y_ = V12 .* outB0;
        %--------------------------------------------------------
        
        
    end
    
    xb = V';
    h2_pred = pinv(xb' * xb) * xb' * Y';
    
    Y_pred = conv(X, h0_pred, 'same') .* conv(f(X, h2_pred), h1_pred, 'same');
    
    e(l) = sum(power((Y - Y_pred), 2));
 
end
 
end
 
 
function [ Y ] = f(X, h)
 
Y = zeros(1, length(X));
 
for i = 1:length(X)   
        for j = 1:length(h)
                Y(i) = Y(i) + h(j) * power(abs(X(i)), j-1);
        end
end
 
end
 

#-----------------------------------------------------------------------------------------------------------------
#for real linear (1 blocks)

function [ h2 ] = Matrix_LMS_2(X)
 
epoch = 100000
 
h0 = [0.1,0.2,0.3]
h1 = [0.4,0.2,0.1]
h2 = [0.1,0.2,0.3]
 
%%
Y = f(X, h2);
L = length(X);
 
 
e = zeros(1, length(X));
 
h1_pred = [0,1,0];
h2_pred = [0,1,0];
for l = 1:epoch
    
    
    
    % h2----------------------------------------------      

    %Vandermond matrix construction
    V = zeros(3, L);
    V1 = zeros(3, L);
    
    D = 1;
    %h1_pred = fliplr(h1);
    for k = -D:D
        V(k + D + 1, :) = power(abs(X), k + D);
        
        % correction test---------------------------------------
        V1(k + D + 1, :) = power(abs(X), k + D);  
        V12 = sum(V1);
        Y_ = V12;
        %--------------------------------------------------------
        
        
    end
    
    xb = V';
    h2_pred = pinv(xb' * xb) * xb' * Y';
    
    Y_pred = conv(f(X, h2_pred), h1_pred, 'same');
    
    e(l) = sum(power((Y - Y_pred), 2));
 
end
 
end
 
 
function [ Y ] = f(X, h)
 
Y = zeros(1, length(X));
 
for i = 1:length(X)   
        for j = 1:length(h)
                Y(i) = Y(i) + h(j) * power(abs(X(i)), j-1);
        end
end
 
end
 








##-------------------------------------------------------------------------------------------------------------

function [ h0 ] = Levenberg_nonliear(X, D)
%LEVENBERV_NONLIEAR Summary of this function goes here
%   Detailed explanation goes here
 
%% for real numbers
% t = linspace(0.1, 100, 1000);
% X = sin(t);
%  
% h0 = [0.1,0.2,0.3];
% h1 = [0,0.2,0.1];
% h2 = [0.1,0.2,0.3];
% 
% D = model(X, h0, h1, h2);
% 
% h0_pred = [0,1,0];
% h1_pred = [0,1,0];
% h2_pred = [.3,1,.3];
 
%% for Complex numbers
 
X = X ./ power(2, 16); 
D = D ./ power(2, 16); 

h0 = [.1+.2i,.2+.3i,.3+.4i];
h1 = [0+0i,-.3+.2i,.1+.2i];
h2 =  [.3+.1i,.2+.3i,.1+.3i];

X = X;
D = D;
%D = model(X, h0, h1, h2);
 
h0_pred = [0+0i,1+1i,0+0i];
h1_pred = [0+0i,1+1i,0+0i];
h2_pred = [.3+.3i,1+1i,.3+.3i];

mu = 0.001;
error = [];
h0_hist = [];
h1_hist = [];
h2_hist = [];
 
 
%% Algorithm
Y = model(X, h0_pred, h1_pred, h2_pred);
e = D - Y;


for i = 1:100000
    J = Jacobi(X, h2_pred, h1_pred, h0_pred);
 
    s_rx = J' * J;
    s_rx = pinv(s_rx + mu * eye(size(J,2)) .* s_rx);
    s_ry = J' * e.';
 
    s = s_rx * s_ry;
 
    n = length(h2_pred);
    k = length(h2_pred) + length(h1_pred);
    l = length(h2_pred) + length(h1_pred) + length(h0_pred);
 
    h1_pred = h1_pred + s(1:n).';
    h2_pred = h2_pred + s(n+1:k).';
    h0_pred = h0_pred + s(k+1:l).';
    
    h0_hist(i, :) = h0_pred.';
    h1_hist(i, :) = h1_pred.';
    h2_hist(i, :) = h2_pred.';
 
    Y =  model(X, h0_pred, h1_pred, h2_pred);
    e = D - Y;
 
    error(i) = nmse(Y, D - Y);
    %error(i) = power(sum(D - Y),2);
    current_error = error(i);
 
    if(mod(i, 10) == 0)
        figure(1)
        plot(1:length(D), D .* conj(D), 1:length(D), (D - Y) .* conj(D - Y));
        %plot(1:length(D), D, 1:length(D), Y);

        figure(2);
        plot(error);
        pause(0.01);
        %plot(1:length(D), D, 1:length(D), Y);
        %figure;
        %plot(1:i, error(1:i));.
    end
    
 
end
 
end
 
function [J] = Jacobi(X, h2, h1, h0)
 
    J = [];%zeros(length(X), 6);
    
    outB0 = conv(X, h0, 'same');
    %---------------nonlinear transform. h1, 1:3 colls of Jacobian ---------------------
    n = length(h2);
    outB1 = conv(X, h1, 'same');
    for i = 1:n
       
        %outB1 = conv(delay(X, i - n + 1), h1, 'same');
        %DX_h1 = (i - 1) * delay(X, i - n + 1) .* power(abs(outB1), i - 1) ./ outB1 * h2(i) .* outB0;
        
        if i == 2 
            DX_h1 = abs(outB1) ./ outB1 .* delay(X, i - n + 1) * h2(i) .* outB0;
        else
            DX_h1 = (i-1) * power(abs(outB1), i - 2) .* abs(outB1) ./ outB1.* delay(X, i - n + 1) * h2(i) .* outB0;
        end
        %DX_h2 = conv(DX_h2, h1, 'same');
        
        %DX_h1(isnan(DX_h1)) = 0;
        J(:,end + 1) = DX_h1.';
    end
    
    %---------------nonlinear transform. h2, 4:6 colls of Jacobian ---------------------
    outB1 = abs(conv(X, h1, 'same'));
    k = length(h2) + length(h1);
    for i = n+1:k
       
        DX_h2 = power(outB1, i - n - 1) .* outB0;
        
        J(:,end + 1) = DX_h2.';
    end
    
    
    %---------------linear fir. h0, 7:9 colls of Jacobian ---------------------
    outB2 = f(conv(X, h1, 'same'), h2);
    l = length(h2) + length(h1) + length(h0);
    for i = k+1:l
       
        DX_h0 = delay(X, i - l + 1) .* outB2;
        
        J(:,end + 1) = DX_h0.';
    end
    %--------------------------------test for h1
    X1 = J(:,1) * h1(1);
    X2 = J(:,2) * h1(2);
    X3 = J(:,3) * h1(3);
    out_B1 = X1+X2+X3;
    
    %--------------------------------test for h2
    X4 = J(:,4) * h2(1);
    X5 = J(:,5) * h2(2);
    X6 = J(:,6) * h2(3);
    out_B2 = X4+X5+X6;
    
    %--------------------------------test for h0
%     X7 = J(:,7) * h0(1);
%     X8 = J(:,8) * h0(2);
%     X9 = J(:,9) * h0(3);
%     out_B2 = X7+X8+X9;
    
    % own function
    %Y1 = convolution(X, h0, 0) .* convolution(convolution(X, h2, 1), h1, 0);
    % matlab conv
    Y2 = model(X, h0, h1, h2);
    % correction test
    %Y__ = out_B1 .* out_B1_;
 
end
 
 
function [Y] = model(X, h0, h1, h2)
    Y = f(conv(X, h1, 'same'), h2) .* conv(X, h0, 'same');
end
 
 
function [Y] = f(X, h)
 
    Y = zeros(1, length(X));
 
    for i = 1:length(X)   
            for j = 1:length(h)
                    Y(i) = Y(i) + h(j) * power(abs(X(i)), j-1);
            end
    end
 
end
 
 

















